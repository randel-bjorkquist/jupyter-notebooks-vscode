{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd1345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09396b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our dataset\n",
    "# NOTE: the variable 'df' represents 'data frame'\n",
    "#full_path = \"C:\\\\Users\\\\randel.bjorkquist\\\\Documents\\\\QuickStart\\\\DataScience\\\\Student_Performance.csv\"\n",
    "#df = pd.read_csv(full_path, parse_dates=['Test_Date'])\n",
    "\n",
    "df = pd.read_csv('./data/admissions.csv', parse_dates=['application_date'], dtype={'approved': 'boolean'})\n",
    "#df = pd.read_csv('./data/admissions.csv', dtype={'application_date': 'datetime64[ns]'}, dtype={'approved': 'boolean'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81557563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "#NOTE: Check if there are any duplicated rows\n",
    "print('\\nNumber of duplicationed rows:', df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"describe\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique Values per Column')\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b8a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['age'], bins=10)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['income'], vert = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5df1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['income'], bins=20)\n",
    "plt.title('Income Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f556da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['region'])\n",
    "plt.title('Region Distribution')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd41cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df['age'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1071c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='region', y='income', data=df)\n",
    "plt.title('Income Distribution by Region')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fefd264",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='region', y='age', hue='approved', kind='box', data=df)\n",
    "plt.title('Age Distribution by Region and Approval Status') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a609bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='region', y='credit_score', hue='approved', kind='bar', data=df)\n",
    "plt.title('Average Credit Score by Region and Approval Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "north = df[df.region == 'North']\n",
    "south = df[df.region == 'South']\n",
    "east = df[df.region == 'East']\n",
    "west = df[df.region == 'West']\n",
    "\n",
    "print('North Region:')\n",
    "print(north.describe())\n",
    "\n",
    "print('South Region:')\n",
    "print(south.describe())\n",
    "\n",
    "print('East Region:')\n",
    "print(east.describe())\n",
    "\n",
    "print('West Region:')\n",
    "print(west.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['age', 'income', 'credit_score', 'employed', 'approved']\n",
    "num_df   = df[num_cols].copy()\n",
    "\n",
    "corr = num_df.corr(method='pearson' )\n",
    "print(corr.round(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['income']\n",
    "y = df['credit_score']\n",
    "\n",
    "plt.scatter(x, y, c=df['approved']\n",
    "   .map({True: 'green', False: 'red'}), alpha=0.75)\n",
    "\n",
    "m,b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b, color='blue', label='Trend Line')\n",
    "\n",
    "\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Credit Score')\n",
    "plt.title('Income vs Credit Score')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns that we want to keep ...\n",
    "columns_to_keep = ['age', 'income', 'credit_score', 'employed', 'region', 'approved']\n",
    "cleaned_df = df[columns_to_keep].copy()\n",
    "\n",
    "cleaned_df.head()\n",
    "#cleaned_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defa185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values for numeric columns:\n",
    "df['age']    = df['age'].fillna(df['age'].median())\n",
    "df['income'] = df['income'].fillna(df['income'].median())\n",
    "df['credit_score'] = df['credit_score'].fillna(df['credit_score'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe84726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: all values within a row must be identical to be considered a duplicate\n",
    "#Drop rows with duplicate values \n",
    "print('\\nNumber of duplicated rows:', df.duplicated().sum())\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe26dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create features for the dataframes\n",
    "#df['age_squared'] = df['age'] ** 2\n",
    "#df['income_log'] = np.log1p(df['income'])\n",
    "#df['credit_score_bin'] = pd.cut(df['credit_score'], bins=[0, 600, 700, 800, 900], labels=[1, 2, 3, 4])\n",
    "#df['is_employed'] = df['employed'].apply(lambda x: 1 if x == True else 0)\n",
    "#df['application_month'] = df['application_date'].dt.month\n",
    "\n",
    "# Create a new binary feature 'high_risk' based on credit score and income\n",
    "#df['high_risk'] = (df['credit_score'] < 300).astype(int)\n",
    "df['high_risk'] = ((df['credit_score'] < 300) & (df['income'] < 20000)).astype(int)\n",
    "\n",
    "\n",
    "#df['high_risk'] = (df['credit_score'] < 300).astype(bool)\n",
    "#df['high_risk'] = df['credit_score'].apply(lambda x: 1 if x < 600 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba56714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b11f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['approved', 'application_date'])\n",
    "y = df['approved']\n",
    "\n",
    "print(X.shape, y.shape) # OUTPUTs: X.shape = (300, 6) Y.shape = (300, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the region column to one-hot encoding\n",
    "#X = pd.get_dummies(X, columns=['region'], drop_first=True)\n",
    "X = pd.get_dummies(X, columns=['region'])\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc47e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need training data ... split the data into training and testing sets: X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify=y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a73fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#NOTE: Training ...\n",
    "#      X_train and show it the corresponding Y_train values ...\n",
    "#      y_test is the actual values for the test data ...\n",
    "#      y_pred is what the model predicts for the X_test data ...\n",
    "\n",
    "y_pred   = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebae3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall    = recall_score(y_test, y_pred)\n",
    "f1        = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ae922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model  import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalre feature without mean\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bbb68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b9749",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred, zero_division = 0)\n",
    "recall    = recall_score(y_test, y_pred)\n",
    "f1        = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\" ,precision)\n",
    "print(\"Recall:\"    ,recall)\n",
    "print(\"F1 Score:\"  ,f1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ed65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering Techniques for Machine Learning Models\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d482428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, chi2, f_classif, VarianceThreshold\n",
    "from sklearn.preprocessing     import MinMaxScaler # Scale features to [0, 1] range for chi-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information Gain Selection Method\n",
    "mi_scores = mutual_info_classif(X, y, random_state = 42)\n",
    "mi_series = pd.Series(mi_scores, index = X.columns).sort_values(ascending = False)\n",
    "\n",
    "print(\"Top 3 Features by information Gain:\")\n",
    "print(mi_series.head(3))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"All Series information Gain:\")\n",
    "print(mi_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4228f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi2_values, chi2_pvalues = chi2(X_scaled, y)\n",
    "\n",
    "#NOTE: We only need the chi2_values for feature ranking and thus we use _ for the p-values, which means we are ignoring them.\n",
    "chi2_values, _ = chi2(X_scaled, y)\n",
    "chi2_series = pd.Series(chi2_values, index = X.columns).sort_values(ascending = False)\n",
    "\n",
    "print(\"Top 3 Features by Chi-Squared Test:\")\n",
    "print(chi2_series.head(3))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"All Series Chi-Squared Test:\")\n",
    "print(chi2_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fisher Score Selection Method\n",
    "f_values, _ = f_classif(X, y)\n",
    "f_series = pd.Series(f_values, index = X.columns).sort_values(ascending = False)\n",
    "\n",
    "print(\"Top 3 Features by Fisher Score:\")\n",
    "print(f_series.head(3))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"All Series Fisher Score:\")\n",
    "print(f_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d27f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variance Thresholding\n",
    "selector = VarianceThreshold(threshold = 0.0) # Set threshold as needed\n",
    "X_reduced = selector.fit_transform(X)\n",
    "\n",
    "print(\"Original number of features:\" ,X.shape[1])\n",
    "print(\" Reduced number of features:\" ,X_reduced.shape[1])\n",
    "\n",
    "print()\n",
    "\n",
    "#NOTE: not sure what the different, if there is any ...\n",
    "#variances = selector.fit(X).variances_\n",
    "#var_series = pd.Series(variances, index = X.columns).sort_values(ascending = False)\n",
    "selector.fit(X)\n",
    "var_series = pd.Series(selector.variances_, index = X.columns).sort_values(ascending = False)\n",
    "\n",
    "print(\"Top 3 Features by Fisher Score:\")\n",
    "print(var_series.head(3))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"All Series Fisher Score:\")\n",
    "print(var_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff49c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for threshold in [0.0, 0.01, 0.05]:\n",
    "for threshold in [0.0, 0.01, 0.1]:\n",
    "    selector = VarianceThreshold(threshold = threshold)\n",
    "    X_reduced = selector.fit_transform(X)\n",
    "    kept_features = X.columns[selector.get_support()]\n",
    "\n",
    "    print(f\"Threshold: {threshold:.2f} => Number of features: {X_reduced.shape[1]}\")\n",
    "    print(f\"Kept features: {list(kept_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now variance test\n",
    "#from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector0 = VarianceThreshold(threshold = 0.1).fit(X)\n",
    "var0 = pd.Series(selector0.variances_, index=X.columns)\n",
    "\n",
    "selector01 = VarianceThreshold(threshold = 100).fit(X)\n",
    "var01 = pd.Series(selector01.variances_, index=X.columns)\n",
    "\n",
    "print(\"Threshold = 0.1\")\n",
    "print(var0.head(3))\n",
    "\n",
    "print(\"\\nThreshold = 100\")\n",
    "print(var01.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "# Manual variance calculation\n",
    "manual_variances = { }\n",
    "\n",
    "for col in X.columns:\n",
    "    values = X[col].values\n",
    "    mean_val = np.mean(values)\n",
    "    variance = np.mean((values - mean_val) ** 2)   # formula\n",
    "    manual_variances[col] = variance\n",
    "\n",
    "manual_var_series = pd.Series(manual_variances)\n",
    "\n",
    "print(\"Manual variance calculation:\")\n",
    "print(manual_var_series.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f159c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation\n",
    "corrs = { }\n",
    "\n",
    "for col in X.columns:\n",
    "  corr = np.corrcoef(X[col], y)[0, 1]\n",
    "  corrs[col] = abs(corr)\n",
    "\n",
    "corr_series = pd.Series(corrs).sort_values(ascending = False)\n",
    "\n",
    "print(\"Top 3 Features by Correlation with Target:\")\n",
    "print(corr_series.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb051031",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({ \"Information Gain\": mi_series\n",
    "                        ,\"Chi2\": chi2_series\n",
    "                        ,\"Fisher\": f_series\n",
    "                        ,\"Correlation\": corr_series\n",
    "                        ,\"Variance\": var_series })\n",
    "\n",
    "print(\"Feature Selection Results:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "print(df.columns.tolist())\n",
    "\n",
    "#Separate the classes\n",
    "df_majority = df[df['approved'] == False]\n",
    "df_minority = df[df['approved'] == True]\n",
    "\n",
    "print(df_majority.shape)\n",
    "print(df_minority.shape)\n",
    "\n",
    "# Upsample minority class\n",
    "#df_minority_upsampled = resample(df_minority, \n",
    "#                                 replace=True,     # sample with replacement\n",
    "#                                 n_samples=len(df_majority),    # to match majority class\n",
    "#                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "#df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Display new class counts\n",
    "#print(df_upsampled['approved'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e9cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resampling Techniques\n",
    "df_minority_upsampled = resample( df_minority\n",
    "                                 ,replace = True                # sample with replacement\n",
    "                                 ,n_samples = len(df_majority)  # to match majority class\n",
    "                                 ,random_state = 42 )           # reproducible results\n",
    "\n",
    "df_minority_upsampled.shape\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "#df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Display new class counts\n",
    "#print(df_upsampled['approved'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
    "print(df_balanced['approved'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_balanced = df_balanced.drop(columns=['approved', 'application_date', 'high_risk', 'region'])\n",
    "y_balanced = df_balanced['approved']\n",
    "\n",
    "print(X_balanced.shape, y_balanced.shape) # OUTPUTs: X.shape = (300, 6) Y.shape = (300, )\n",
    "X_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size = 0.2, random_state = 42, stratify=y_balanced)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8081e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, zero_division = 0))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, zero_division = 0))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, zero_division = 0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = (y_pred == True) & (y_test == False)\n",
    "false_positives = X_test[indices].copy()\n",
    "print(false_positives)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf92aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'actual': y_test, 'predicted': y_pred}, index = X_test.index)\n",
    "df_with_predictions = df_balanced.join(results, how='left')\n",
    "false_positives = df_with_predictions[(df_with_predictions['actual'] == False) & (df_with_predictions['predicted'] == True)]\n",
    "print(false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grok AI Code ....\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "# Assuming y_test and y_pred are NumPy arrays or Pandas Series\n",
    "# and X_test is a Pandas DataFrame containing the test records\n",
    "\n",
    "# Convert to NumPy arrays if they are Pandas Series\n",
    "y_test = np.array(y_test)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Find indices where actual is 0 and predicted is 1 (False Positives)\n",
    "fp_indices = np.where((y_test == 0) & (y_pred == 1))[0]\n",
    "\n",
    "# If X_test is a DataFrame, get the corresponding records\n",
    "if isinstance(X_test, pd.DataFrame):\n",
    "    fp_records = X_test.iloc[fp_indices]\n",
    "else:\n",
    "    # If X_test is a NumPy array\n",
    "    fp_records = X_test[fp_indices]\n",
    "\n",
    "# Print the records\n",
    "print(\"False Positive Records (actual = 0, predicted = 1):\")\n",
    "print(fp_records)\n",
    "\n",
    "# Optionally, if you want to see the corresponding y_test and y_pred values\n",
    "fp_labels = pd.DataFrame({'y_test': y_test[fp_indices], 'y_pred': y_pred[fp_indices]})\n",
    "print(\"\\nLabels for False Positives:\")\n",
    "print(fp_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
